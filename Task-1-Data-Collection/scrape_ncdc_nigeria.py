# -*- coding: utf-8 -*-
"""Scrape NCDC Nigeria.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bgdUnnZTCwhubeLcL7HJ_14u__Cwm7tO
"""

import requests
from bs4 import BeautifulSoup
import json
import re
import csv

# Function to remove HTML tags from extracted text
def clean_text(html_content):
    soup = BeautifulSoup(html_content, "html.parser")
    return soup.get_text(separator=" ", strip=True)  # Removes HTML and trims extra spaces

# Base URL for the disease fact sheet
base_url = 'https://ncdc.gov.ng/diseases/factsheet'

# Fetch the diseases data from the NCDC API endpoint
api_url = 'https://ncdc.gov.ng/ajax/get_diseases'
response = requests.get(api_url)
diseases = response.json()

# List to store all extracted disease data
disease_data = []

# Iterate over each disease URL
for disease in diseases:
    disease_url = f"{base_url}/{disease['id']}"
    print(f"Scraping data from: {disease_url}")

    # Fetch the HTML content of the disease page
    response = requests.get(disease_url)
    soup = BeautifulSoup(response.content, 'html.parser')

    # Extract the script tag that contains JSON data
    script_tag = soup.find('script', text=re.compile('json_data'))
    if script_tag:
        json_text = re.search(r'json_data\s*=\s*(\[.*?\]);', script_tag.string, re.DOTALL)
        if json_text:
            disease_json = json.loads(json_text.group(1))  # Convert JSON string to Python dict
            disease_info = disease_json[0]

            # Extracting required fields and cleaning HTML tags
            disease_name = clean_text(disease_info.get('disease_name', 'Not found'))
            background = clean_text(disease_info.get('background', 'Not found'))
            transmission = clean_text(disease_info.get('transmission', 'Not found'))
            symptoms = clean_text(disease_info.get('symptoms', 'Not found'))
            diagnosis = clean_text(disease_info.get('diagnosis_testing', 'Not found'))
            treatment = clean_text(disease_info.get('treatment', 'Not found'))

            # Store the cleaned data with the disease URL
            disease_data.append({
                'Disease Name': disease_name,
                'Background': background,
                'Transmission': transmission,
                'Symptoms': symptoms,
                'Diagnosis': diagnosis,
                'Treatment': treatment,
                'URL': disease_url  # Adding URL column
            })
        else:
            print("JSON data not found.")
    else:
        print("Script tag containing JSON data not found.")

# Write the extracted data to a CSV file
csv_file = 'ncdc_diseases.csv'
with open(csv_file, mode='w', newline='', encoding='utf-8') as file:
    writer = csv.DictWriter(file, fieldnames=['Disease Name', 'Background', 'Transmission', 'Symptoms', 'Diagnosis', 'Treatment', 'URL'])
    writer.writeheader()
    for data in disease_data:
        writer.writerow(data)

print(f"Data has been successfully written to {csv_file}")



