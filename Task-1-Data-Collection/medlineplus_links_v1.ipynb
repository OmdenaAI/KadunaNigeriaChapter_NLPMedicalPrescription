{"cells":[{"cell_type":"code","execution_count":null,"id":"d8a7b520-52a8-4a2e-97e5-90651905c0d7","metadata":{"id":"d8a7b520-52a8-4a2e-97e5-90651905c0d7"},"outputs":[],"source":["import requests\n","import time\n","import random\n","import csv\n","import datetime\n","from bs4 import BeautifulSoup\n","\n","# Base URL for MedlinePlus encyclopedia\n","base_url = \"https://medlineplus.gov/ency/\"\n","\n","# URL for the first page (encyclopedia_A.htm)\n","start_url = base_url + \"encyclopedia_A.htm\"\n","\n","# Request and parse the first page to find all section links (A-Z, 0-9)\n","response = requests.get(start_url)\n","soup = BeautifulSoup(response.content, \"html.parser\")\n","\n","# Find all section links (A-Z, 0-9)\n","section_links = []\n","for link in soup.find_all('a', href=True):\n","    href = link['href']\n","    if \"encyclopedia_\" in href and href.endswith(\".htm\"):\n","        full_url = base_url + href\n","        section_links.append(full_url)\n","\n","# Remove the first link from the list\n","section_links = section_links[1:]\n","section_links[0] = 'https://medlineplus.gov/ency/encyclopedia_A.htm'"]},{"cell_type":"code","execution_count":null,"id":"c4c534f6-7ce1-4004-873e-3644582b0b70","metadata":{"id":"c4c534f6-7ce1-4004-873e-3644582b0b70","outputId":"27da7236-1da6-4417-e1f9-6f35cf80270a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Scraping section: A (https://medlineplus.gov/ency/encyclopedia_A.htm)\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[53], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScraping section: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msection_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msection_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Random delay to avoid being flagged as a bot\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muniform\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Request the section page\u001b[39;00m\n\u001b[1;32m     13\u001b[0m response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(section_url)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# Dictionary to store articles for each section\n","all_articles = {}\n","\n","# Get all section link (A-Z, 0-9)\n","for section_url in section_links:\n","    section_name = section_url.split(\"_\")[-1].replace(\".htm\", \"\")\n","    print(f\"Scraping section: {section_name} ({section_url})\")\n","\n","    # Random delay to avoid being flagged as a bot\n","    time.sleep(random.uniform(5, 7))\n","\n","    # Request the section page\n","    response = requests.get(section_url)\n","    soup = BeautifulSoup(response.content, \"html.parser\")\n","\n","# List to store all articles\n","all_articles = []\n","\n","# Scrape each section page for articles\n","for section_url in section_links:\n","    section_name = section_url.split(\"_\")[-1].replace(\".htm\", \"\")  # Extract section name (A, B, etc.)\n","    print(f\"Scraping section: {section_name} ({section_url})\")\n","\n","    # Random delay to avoid being flagged as a bot\n","    time.sleep(random.uniform(5, 7))\n","\n","    # Request the section page\n","    response = requests.get(section_url)\n","    soup = BeautifulSoup(response.content, \"html.parser\")\n","\n","    # Find the article list inside <ul id=\"index\">\n","    article_list = soup.find(\"ul\", {\"id\": \"index\"})  # Locate <ul id=\"index\">\n","\n","    if article_list:\n","        links = article_list.find_all('a')  # Extract all <a> tags inside <ul id=\"index\">\n","\n","        for i in range(len(links)):  # Loop through all links\n","            a_tag = links[i]  # Get each <a> tag\n","\n","            href = a_tag['href']  # Extract the link\n","            title = a_tag.text.strip()  # Extract the title text\n","\n","            # Ensure it's a valid relative URL and prepend the base URL\n","            if href.startswith(\"article/\") or href.startswith(\"patientinstructions/\"):\n","                full_url = base_url + href\n","                all_articles.append((title, full_url))  # Store as (title, URL)\n","\n","# Save data to a CSV file with two columns: \"Title\" and \"URL\"\n","csv_filename = \"medlineplus_articles_link.csv\"\n","\n","with open(csv_filename, mode='w', newline='', encoding='utf-8') as file:\n","    writer = csv.writer(file)\n","    writer.writerow([\"Disease\", \"URL\"])  # Write column headers\n","    writer.writerows(all_articles)  # Write article data\n"]},{"cell_type":"code","execution_count":null,"id":"50b54163-83fc-4711-a6af-269efaee4235","metadata":{"id":"50b54163-83fc-4711-a6af-269efaee4235"},"outputs":[],"source":["# Save data to a CSV file with two columns: \"Title\" and \"URL\"\n","csv_filename = \"medlineplus_articles_link.csv\"\n","\n","with open(csv_filename, mode='w', newline='', encoding='utf-8') as file:\n","    writer = csv.writer(file)\n","    writer.writerow([\"Disease\", \"URL\"])  # Write column headers\n","    writer.writerows(all_articles)  # Write article data"]},{"cell_type":"code","execution_count":null,"id":"17297e3f-6417-418f-b75a-b970c9475b38","metadata":{"id":"17297e3f-6417-418f-b75a-b970c9475b38"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.5"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}