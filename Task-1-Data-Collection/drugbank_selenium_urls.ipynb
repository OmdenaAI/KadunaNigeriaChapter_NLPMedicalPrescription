{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Chrome WebDriver\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless\")  # Run in headless mode for faster execution\n",
    "# options.add_argument(\"--incognito\")  # Prevent tracking\n",
    "\n",
    "# Some websites block automated browsers. So try adding a user-agent string to make Selenium appear as a regular browser\n",
    "options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\")\n",
    "\n",
    "# Use WebDriver Manager instead of manually downloading ChromeDriver\n",
    "# Automatically downloads the correct ChromeDriver version, thus avoiding issues of mismatched driver versions\n",
    "# Install using - conda install conda-forge::webdriver-manager\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base URL\n",
    "base_url = \"https://go.drugbank.com/drugs?approved=1&c=name&d=up&page={}\"\n",
    "page = 1  # Start from page 1\n",
    "\n",
    "# List to store scraped data\n",
    "data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Page 1\n",
      "Finished Page 2\n",
      "Finished Page 3\n",
      "Finished Page 4\n",
      "Finished Page 5\n",
      "Finished Page 6\n",
      "Finished Page 7\n",
      "Finished Page 8\n",
      "Finished Page 9\n",
      "Finished Page 10\n",
      "Finished Page 11\n",
      "Finished Page 12\n",
      "Finished Page 13\n",
      "Finished Page 14\n",
      "Finished Page 15\n",
      "Finished Page 16\n",
      "Finished Page 17\n",
      "Finished Page 18\n",
      "Finished Page 19\n",
      "Finished Page 20\n",
      "Finished Page 21\n",
      "Finished Page 22\n",
      "Finished Page 23\n",
      "Finished Page 24\n",
      "Finished Page 25\n",
      "Finished Page 26\n",
      "Finished Page 27\n",
      "Finished Page 28\n",
      "Finished Page 29\n",
      "Finished Page 30\n",
      "Finished Page 31\n",
      "Finished Page 32\n",
      "Finished Page 33\n",
      "Finished Page 34\n",
      "Finished Page 35\n",
      "Finished Page 36\n",
      "Finished Page 37\n",
      "Finished Page 38\n",
      "Finished Page 39\n",
      "Finished Page 40\n",
      "Finished Page 41\n",
      "Finished Page 42\n",
      "Finished Page 43\n",
      "Finished Page 44\n",
      "Finished Page 45\n",
      "Finished Page 46\n",
      "Finished Page 47\n",
      "Finished Page 48\n",
      "Finished Page 49\n",
      "Finished Page 50\n",
      "Finished Page 51\n",
      "Finished Page 52\n",
      "Finished Page 53\n",
      "Finished Page 54\n",
      "Finished Page 55\n",
      "Finished Page 56\n",
      "Finished Page 57\n",
      "Finished Page 58\n",
      "Finished Page 59\n",
      "Finished Page 60\n",
      "Finished Page 61\n",
      "Finished Page 62\n",
      "Finished Page 63\n",
      "Finished Page 64\n",
      "Finished Page 65\n",
      "Finished Page 66\n",
      "Finished Page 67\n",
      "Finished Page 68\n",
      "Finished Page 69\n",
      "Finished Page 70\n",
      "Finished Page 71\n",
      "Finished Page 72\n",
      "Finished Page 73\n",
      "Finished Page 74\n",
      "Finished Page 75\n",
      "Finished Page 76\n",
      "Finished Page 77\n",
      "Finished Page 78\n",
      "Finished Page 79\n",
      "Finished Page 80\n",
      "Finished Page 81\n",
      "Finished Page 82\n",
      "Finished Page 83\n",
      "Finished Page 84\n",
      "Finished Page 85\n",
      "Finished Page 86\n",
      "Finished Page 87\n",
      "Finished Page 88\n",
      "Finished Page 89\n",
      "Finished Page 90\n",
      "Finished Page 91\n",
      "Finished Page 92\n",
      "Finished Page 93\n",
      "Finished Page 94\n",
      "Finished Page 95\n",
      "Finished Page 96\n",
      "Finished Page 97\n",
      "Finished Page 98\n",
      "Finished Page 99\n",
      "Finished Page 100\n",
      "Finished Page 101\n",
      "Finished Page 102\n",
      "Finished Page 103\n",
      "Finished Page 104\n",
      "Finished Page 105\n",
      "Finished Page 106\n",
      "Finished Page 107\n",
      "Finished Page 108\n",
      "Finished Page 109\n",
      "Finished Page 110\n",
      "Finished Page 111\n",
      "Finished Page 112\n",
      "Finished Page 113\n",
      "No more drugs found on page 114. Stopping...\n",
      "ðŸŽ‰ Scraping complete! Data saved to drugbank_drugs.csv\n"
     ]
    }
   ],
   "source": [
    "# Loop through all 113 pages\n",
    "while True:\n",
    "\n",
    "    url = base_url.format(page)\n",
    "    driver.get(url)\n",
    "    time.sleep(2)  # Allow page to load\n",
    "\n",
    "    # Find all drug links (more robust method)\n",
    "    drug_elements = driver.find_elements(By.XPATH, '//td[contains(@class, \"drug-name\")]/strong/a[contains(@href, \"/drugs/\")]')\n",
    "\n",
    "    if not drug_elements:  # Stop when no more results are found\n",
    "        print(f\"No more drugs found on page {page}. Stopping...\")\n",
    "        break\n",
    "\n",
    "    for element in drug_elements:\n",
    "        try:\n",
    "            drug_name = element.text.strip()  # Extract drug name\n",
    "            drug_link = element.get_attribute(\"href\")  # Extract href link\n",
    "\n",
    "            # Store the extracted data\n",
    "            data.append({\"Drug Name\": drug_name, \"Drug URL\": drug_link})\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error on page {page}: {e}\")\n",
    "\n",
    "    print(f\"Finished Page {page}\")\n",
    "    page += 1  # Move to the next page\n",
    "\n",
    "    if page % 50 == 0:\n",
    "        time.sleep(random.uniform(20, 50))\n",
    "\n",
    "    # Restart driver, Selenium may slow down or crash\n",
    "    if page % 100 == 0:  # Restart every 100 pages\n",
    "        driver.quit()\n",
    "        driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "    # Convert to DataFrame and save as CSV after every 10 pages\n",
    "    if page % 10 == 0:\n",
    "        df = pd.DataFrame(data)\n",
    "        df.to_csv(\"drugbank_selenium_drugs.csv\", index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Convert to DataFrame and save as CSV\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(\"drugbank_selenium_drugs.csv\", index=False)\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n",
    "\n",
    "print(\"ðŸŽ‰ Scraping complete! Data saved to drugbank_drugs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
