{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "978b8ccc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped 849 drugs from letter A\n",
      "Scraped 1248 drugs from letter B\n",
      "Scraped 1973 drugs from letter C\n",
      "Scraped 2520 drugs from letter D\n",
      "Scraped 2970 drugs from letter E\n",
      "Scraped 3338 drugs from letter F\n",
      "Scraped 3539 drugs from letter G\n",
      "Scraped 3796 drugs from letter H\n",
      "Scraped 4162 drugs from letter I\n",
      "Scraped 4206 drugs from letter J\n",
      "Scraped 4330 drugs from letter K\n",
      "Scraped 4806 drugs from letter L\n",
      "Scraped 5342 drugs from letter M\n",
      "Scraped 5747 drugs from letter N\n",
      "Scraped 6018 drugs from letter O\n",
      "Scraped 6657 drugs from letter P\n",
      "Scraped 6705 drugs from letter Q\n",
      "Scraped 7045 drugs from letter R\n",
      "Scraped 7509 drugs from letter S\n",
      "Scraped 8153 drugs from letter T\n",
      "Scraped 8221 drugs from letter U\n",
      "Scraped 8500 drugs from letter V\n",
      "Scraped 8525 drugs from letter W\n",
      "Scraped 8597 drugs from letter X\n",
      "Scraped 8618 drugs from letter Y\n",
      "Scraped 8797 drugs from letter Z\n",
      "CSV file has been written successfully!\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "base_url = \"https://www.rxlist.com/drugs/alpha_{}.htm\"\n",
    "letters = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "\n",
    "drugs_data = []\n",
    "\n",
    "for letter in letters:\n",
    "    url = base_url.format(letter)\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to fetch {url}\")\n",
    "        continue\n",
    "    \n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    for link in soup.select(\".AZ_results ul li a\"):  # Fix: Use class instead of ID\n",
    "        drug_name = link.text.strip()\n",
    "        drug_url = link[\"href\"]\n",
    "        drugs_data.append([drug_name, drug_url])\n",
    "\n",
    "    print(f\"Scraped {len(drugs_data)} drugs from letter {letter.upper()}\")\n",
    "\n",
    "# Write to CSV\n",
    "with open('RxList.csv', 'w', newline='', encoding='utf-8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['Drug Name', 'URL'])\n",
    "    writer.writerows(drugs_data)\n",
    "\n",
    "print(\"CSV file has been written successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf567f0a-2b65-42e9-b344-2299fe7f67c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
